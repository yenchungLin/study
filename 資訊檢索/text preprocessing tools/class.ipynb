{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "/Users/yulin/stanza_resources\n"
    }
   ],
   "source": [
    "import stanza\n",
    "from stanza.utils.resources import DEFAULT_MODEL_DIR\n",
    "print(DEFAULT_MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'stanza' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-905bb455b334>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# download English model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstanza\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# download traditional Chinese model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstanza\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'zh-hant'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stanza' is not defined"
     ]
    }
   ],
   "source": [
    "# download English model\n",
    "stanza.download('en')\n",
    "# download traditional Chinese model\n",
    "stanza.download('zh-hant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text\n",
    "en_doc = 'On April 3, the Central Epidemic Command Center (CECC) reported that that 827 additional cases related to coronavirus disease 2019 (COVID-19) were reported on April 2.'\n",
    "zh_doc = '中央流行疫情指揮中心今(3)日表示，昨(2)日國內新增827例新型冠狀病毒肺炎相關通報， 截至目前累計34,557例(含30,530例排除)，其中348例確診(今日新增案340至348)，分別為 298例境外移入及50例本土病例。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'stanza' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-97c5d8cdbe0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# initialize English neural pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0men_nlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstanza\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'en'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprocessors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tokenize,lemma,pos'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# initialize Chinese neural pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mzh_nlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstanza\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'zh-hant'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprocessors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tokenize,lemma,pos'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stanza' is not defined"
     ]
    }
   ],
   "source": [
    "# initialize English neural pipeline\n",
    "en_nlp = stanza.Pipeline(lang = 'en',processors = 'tokenize,lemma,pos',use_gpu = False)\n",
    "# initialize Chinese neural pipeline\n",
    "zh_nlp = stanza.Pipeline(lang = 'zh-hant',processors = 'tokenize,lemma,pos',use_gpu = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'en_nlp' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d4d8eaacd785>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run annotation over a English sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0men_annotated_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0men_nlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_doc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# run annotation over a Chinese sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mzh_annotated_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzh_nlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzh_doc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'en_nlp' is not defined"
     ]
    }
   ],
   "source": [
    "# run annotation over a English sentence\n",
    "en_annotated_doc = en_nlp(en_doc)\n",
    "# run annotation over a Chinese sentence\n",
    "zh_annotated_doc = zh_nlp(zh_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(doc):\n",
    "    for i,sent in enumerate(doc.sentence):\n",
    "        print (\"Sentence {}\\nINDEX\\tTEXT\\tPOS\".format(i+1))\n",
    "        for j,word in enumerate(sent.words):\n",
    "            print(\"{}\\t{}\\t{}\\t{}\".format(j,word.text,word.lemma,word.pos))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "print('English annotation')\n",
    "show(en_annotated_doc)\n",
    "\n",
    "print('Chinese annotation')\n",
    "show(zh_annotated_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ckiptagger import data_utils,construct_dictionary,WS,POS,NER\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download traditional Chinese model\n",
    "path = str(Path.home())+'/ckip/'\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "    data_utils.downlaod_data_gdown(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text\n",
    "zh_doc = '中央流行疫情指揮中心今(3)日表示，昨(2)日國內新增827例新型冠狀病毒肺炎相關通報， 截至目前累計34,557例(含30,530例排除)，其中348例確診(今日新增案340至348)，分別為 298例境外移入及50例本土病例。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize Chinese neural pipeline\n",
    "zh_ws = WS(path+\"/data\")\n",
    "zh_pos = POS(path+/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run annotation over a Chinese sentence\n",
    "zh_annotated_ws = zh_ws([zh_doc])\n",
    "zh_annotated_pos = zh_pos(zh_annotated_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Chinese annotation')\n",
    "for i,sentence in enumerate(zip(zh_annotated_ws,zh_annotated_pos)):\n",
    "    print('sentence {}:'.format(i))\n",
    "    print('INDEX\\tTEXT\\tPOS')\n",
    "    for j,word in enumerate(zip(sentence[0],sentence[1])):\n",
    "        print('{}\\t{}\\t{}'.format(j,word[0],word[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import os\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download tranditional Chinese dictionary\n",
    "URL = 'https://githud.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.big'\n",
    "if not os.ath.exists(os.path.join(os.getcwd(),'dict.txt.big')):\n",
    "    urllib.request.urlretrieve(URL,'dict.txt.big')\n",
    "\n",
    "# jieba.set_dictionary('dict.txt.big)\n",
    "# jieba.load_userdict('userdict.txt)\n",
    "#     jieba.add_word('國內')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text\n",
    "zh_doc = '中央流行疫情指揮中心今(3)日表示，昨(2)日國內新增827例新型冠狀病毒肺炎相關通報， 截至目前累計34,557例(含30,530例排除)，其中348例確診(今日新增案340至348)，分別為 298例境外移入及50例本土病例。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}